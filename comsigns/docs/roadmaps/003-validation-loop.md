# üó∫Ô∏è Roadmap: Validaci√≥n y Diagn√≥stico de Generalizaci√≥n

> **Fecha**: 20 de enero de 2026  
> **Estado**: ‚úÖ Completado  
> **M√≥dulo**: `comsigns.training` + `comsigns.core.data`

---

## üìã Contexto del Problema

El sistema ComSigns tiene un trainer funcional que demostr√≥:
- ‚úÖ Loss disminuye en modo overfit (~6.3 ‚Üí ~0.001)
- ‚úÖ Gradientes no nulos
- ‚úÖ Shapes correctos

**Problema**: No sabemos si el modelo **generaliza** o solo **memoriza**.

**Soluci√≥n**: Implementar train/validation split y medir ambos losses.

---

## üéØ Objetivos

| ID | Objetivo | Prioridad |
|----|----------|-----------|
| O1 | Crear split train/validation (80/20) | Alta |
| O2 | Implementar validation loop (forward-only) | Alta |
| O3 | Loggear train_loss y val_loss por epoch | Alta |
| O4 | Mantener backward compatibility (validate=False) | Media |

### No-Objetivos (expl√≠citamente excluidos)

- ‚ùå Test set
- ‚ùå M√©tricas avanzadas (accuracy, WER, BLEU)
- ‚ùå Early stopping
- ‚ùå Checkpoints
- ‚ùå Learning rate schedulers
- ‚ùå Data augmentation
- ‚ùå Cambios de arquitectura

---

## üèóÔ∏è Dise√±o Propuesto

### Arquitectura de Archivos

```
comsigns/
‚îú‚îÄ‚îÄ core/data/
‚îÇ   ‚îî‚îÄ‚îÄ splits.py           # NUEVO: funciones de split
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ config.py           # MODIFICAR: agregar validate flag
‚îÇ   ‚îú‚îÄ‚îÄ loops.py            # MODIFICAR: agregar validate_one_epoch
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py          # MODIFICAR: integrar validaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ validation.py       # NUEVO (opcional): l√≥gica de validaci√≥n
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ train.py            # MODIFICAR: usar split
```

### Flujo de Datos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     random_split      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AECDataset ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂  ‚îÇ train_set   ‚îÇ (80%)
‚îÇ   (full)    ‚îÇ                       ‚îÇ val_set     ‚îÇ (20%)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº                       ‚ñº                       
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇtrain_loader ‚îÇ         ‚îÇ val_loader  ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                       ‚îÇ
                    ‚ñº                       ‚ñº
            train_one_epoch()       validate_one_epoch()
                    ‚îÇ                       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                    Epoch X | Train: Y.YY | Val: Z.ZZ
```

### Componentes

#### 1. `create_train_val_split()` (splits.py)

```python
def create_train_val_split(
    dataset: Dataset,
    val_ratio: float = 0.2,
    seed: Optional[int] = 42
) -> Tuple[Subset, Subset]:
    """Split dataset into train and validation sets."""
```

**Decisiones**:
- Usar `torch.utils.data.random_split` (est√°ndar PyTorch)
- NO estratificar (simplificaci√≥n inicial)
- Seed configurable para reproducibilidad

#### 2. `validate_one_epoch()` (loops.py)

```python
def validate_one_epoch(
    model: nn.Module,
    dataloader: DataLoader,
    loss_fn: nn.Module,
    device: torch.device
) -> float:
    """Forward-only validation pass."""
```

**Reglas**:
- `model.eval()`
- `torch.no_grad()`
- NO backward, NO optimizer
- Retorna loss promedio

#### 3. `TrainerConfig` actualizado

```python
@dataclass
class TrainerConfig:
    # ... existing fields ...
    validate: bool = True
    val_ratio: float = 0.2
```

#### 4. `Trainer.fit()` modificado

```python
def fit(self, dataset_or_loader, val_loader=None):
    if self.config.validate and val_loader is None:
        # Auto-split if dataset passed
        train_set, val_set = create_train_val_split(dataset)
        train_loader = DataLoader(train_set, ...)
        val_loader = DataLoader(val_set, ...)
    
    for epoch in range(epochs):
        train_loss = train_one_epoch(...)
        val_loss = validate_one_epoch(...) if val_loader else None
        log(train_loss, val_loss)
```

---

## üîß Decisiones T√©cnicas

### 1. Split fuera del Dataset

**Raz√≥n**: Clean Architecture - el Dataset no debe saber sobre splits.

```python
# ‚úÖ Correcto: split externo
train_set, val_set = random_split(dataset, [0.8, 0.2])

# ‚ùå Incorrecto: split dentro del dataset
dataset = AECDataset(split="train")  # NO
```

### 2. No estratificar inicialmente

**Raz√≥n**: 
- Simplificaci√≥n para diagn√≥stico inicial
- El dataset AEC puede tener distribuci√≥n desbalanceada
- Estratificaci√≥n es optimizaci√≥n prematura aqu√≠

### 3. Validation loop separado

**Raz√≥n**: Single Responsibility Principle

```python
# ‚úÖ Correcto: funci√≥n separada
val_loss = validate_one_epoch(model, val_loader, loss_fn, device)

# ‚ùå Incorrecto: flag en train_one_epoch
train_one_epoch(..., is_validation=True)  # NO
```

### 4. Backward compatibility con `validate=False`

**Raz√≥n**: No romper el modo overfit existente.

```python
if config.validate:
    val_loss = validate_one_epoch(...)
else:
    val_loss = None  # Comportamiento anterior
```

---

## üìÅ Archivos a Crear / Modificar

| Archivo | Acci√≥n | Prop√≥sito | Estado |
|---------|--------|-----------|--------|
| `core/data/splits.py` | CREAR | Funciones de split | ‚è≥ |
| `core/data/__init__.py` | MODIFICAR | Exportar splits | ‚è≥ |
| `training/loops.py` | MODIFICAR | Agregar `validate_one_epoch` | ‚è≥ |
| `training/config.py` | MODIFICAR | Agregar `validate`, `val_ratio` | ‚è≥ |
| `training/trainer.py` | MODIFICAR | Integrar validaci√≥n en `fit()` | ‚è≥ |
| `scripts/train.py` | MODIFICAR | Usar split train/val | ‚è≥ |
| `tests/unit/test_validation.py` | CREAR | Tests de validaci√≥n | ‚è≥ |

---

## üß™ Plan de Testing

### Tests Unitarios

| Test | Descripci√≥n | Estado |
|------|-------------|--------|
| `test_split_ratios` | Split respeta 80/20 | ‚è≥ |
| `test_split_reproducibility` | Mismo seed = mismo split | ‚è≥ |
| `test_validate_one_epoch_no_grad` | No hay gradientes en validaci√≥n | ‚è≥ |
| `test_validate_returns_float` | Retorna loss promedio | ‚è≥ |
| `test_trainer_with_validation` | Trainer loggea train y val loss | ‚è≥ |
| `test_trainer_validate_false` | Trainer funciona sin validaci√≥n | ‚è≥ |

### Validaciones de Diagn√≥stico

| Escenario | train_loss | val_loss | Interpretaci√≥n |
|-----------|------------|----------|----------------|
| Sano | ‚Üì | ‚Üì | ‚úÖ Modelo generaliza |
| Overfitting | ‚Üì | ‚Üë | ‚ö†Ô∏è Necesita regularizaci√≥n |
| Underfitting | ‚âà | ‚âà | ‚ö†Ô∏è Modelo muy simple o LR bajo |

---

## üí° Ejemplo de Uso Final

```python
# Opci√≥n 1: Trainer hace el split autom√°ticamente
trainer = Trainer(model, TrainerConfig(validate=True, val_ratio=0.2))
history = trainer.fit(dataset)  # Pasa dataset completo

# Opci√≥n 2: Usuario hace el split manualmente
train_set, val_set = create_train_val_split(dataset)
train_loader = DataLoader(train_set, ...)
val_loader = DataLoader(val_set, ...)
history = trainer.fit(train_loader, val_loader=val_loader)
```

### Output Esperado

```
============================================================
Epoch 1/5
============================================================
Epoch 1 | Step 10/50 | Loss: 6.2341
Epoch 1 | Step 20/50 | Loss: 5.8923
...
Epoch 1 | Train Loss: 5.4321 | Val Loss: 5.6789

============================================================
Epoch 5/5
============================================================
...
Epoch 5 | Train Loss: 1.2345 | Val Loss: 1.8765

Training complete!
  Train Loss: 6.34 ‚Üí 1.23
  Val Loss: 6.12 ‚Üí 1.88
  ‚úÖ Modelo est√° aprendiendo
```

---

## üìä M√©tricas de √âxito

| M√©trica | Criterio | Estado |
|---------|----------|--------|
| Split correcto | `len(train) + len(val) == len(dataset)` | ‚úÖ |
| Reproducibilidad | Mismo seed ‚Üí mismo split | ‚úÖ |
| Validaci√≥n sin gradientes | `param.grad is None` despu√©s de val | ‚úÖ |
| Logging correcto | Train y Val loss aparecen | ‚úÖ |
| Backward compatible | `validate=False` funciona como antes | ‚úÖ |

---

## ‚úÖ Resultados de Implementaci√≥n

**Tests creados**: 19 tests en `tests/unit/test_validation.py`

**Archivos creados/modificados**:
- `core/data/splits.py` - NUEVO: funciones de split
- `core/data/__init__.py` - NUEVO: exports
- `training/config.py` - MODIFICADO: validate, val_ratio
- `training/loops.py` - MODIFICADO: validate_one_epoch
- `training/trainer.py` - MODIFICADO: integraci√≥n validaci√≥n
- `scripts/train.py` - MODIFICADO: --no-validate, --val-ratio

**Total tests pasando**: 41 (22 trainer + 19 validation)

---

## üîú Pr√≥ximos Pasos (fuera de scope)

1. Estratificaci√≥n del split por clase
2. Test set separado
3. M√©tricas (accuracy, top-k)
4. Early stopping basado en val_loss
5. Checkpointing del mejor modelo

---

## üìö Referencias

- [PyTorch random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split)
- Trainer actual: `training/trainer.py`
- Loops actuales: `training/loops.py`
